#!/usr/bin/env python3
"""
üöÄ CrewAI Avalia√ß√£o Completa de Codebase
========================================

Sistema plug-and-play para an√°lise profissional de codebase usando Gemini 2.5 Flash.
Gera relat√≥rios ultra-profissionais para devs juniores e seniores.

Fluxo: Codebase ‚Üí Script Python ‚Üí Relat√≥rio ‚Üí CrewAI ‚Üí Relat√≥rio Ultra-Profissional
"""

from crewai import Agent, Task, Crew, Process
try:
    import crewai_tools
    HAVE_CREWAI_TOOLS = True
except Exception:
    crewai_tools = None
    HAVE_CREWAI_TOOLS = False
from dotenv import load_dotenv
import os
import json
from datetime import datetime
from typing import Dict, List, Optional
import logging

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Carrega vari√°veis de ambiente
load_dotenv()

class CodebaseAnalysisCrew:
    """
    ü§ù CrewAI para Avalia√ß√£o Completa de Codebase
    
    Roles especializados:
    üìê Arquiteto de Software
    üß™ Engenheiro de Qualidade  
    üìÑ Documentador T√©cnico
    üöÄ Product Manager
    ‚öñÔ∏è Especialista Legal
    ü§ñ Engenheiro de IA
    """
    
    def __init__(self, gemini_api_key: Optional[str] = None):
        """Inicializa a crew com configura√ß√£o Gemini 2.5 Flash"""
        self.gemini_api_key = gemini_api_key or os.getenv("GEMINI_API_KEY")
        if not self.gemini_api_key:
            raise ValueError("‚ùå GEMINI_API_KEY n√£o encontrada! Configure no .env ou passe como par√¢metro")
        
        # Remove espa√ßos em branco da API key se houver
        self.gemini_api_key = self.gemini_api_key.strip()
        
        logger.info(f"‚úÖ GEMINI_API_KEY carregada: {self.gemini_api_key[:10]}...")
        
        # Set environment variables for CrewAI's built-in LLM handling
        # Following the pattern from latest_ai_development example
        os.environ["GEMINI_API_KEY"] = self.gemini_api_key
        if "MODEL" not in os.environ:
            os.environ["MODEL"] = "gemini/gemini-2.5-flash"
        
        # CrewAI will automatically handle LLM instantiation from env vars
        # No need for manual LLM() instantiation
        self.llm = None
        
        # Tools para leitura de arquivos (s√≥ instanciaremos ferramentas reais se dispon√≠veis)
        if HAVE_CREWAI_TOOLS and crewai_tools is not None:
            try:
                self.file_tool = crewai_tools.FileReadTool()
                self.dir_tool = crewai_tools.DirectoryReadTool()
            except Exception:
                # se qualquer erro ao instanciar, ca√≠mos para None e usamos leitura direta
                self.file_tool = None
                self.dir_tool = None
        else:
            self.file_tool = None
            self.dir_tool = None
        
        # Cria agentes especializados
        self.agents = self._create_agents()
        self.tasks = self._create_tasks()
        
    def _create_agents(self) -> Dict[str, Agent]:
        """üé≠ Cria todos os agentes especializados"""
        tools_list = [self.file_tool, self.dir_tool] if (self.file_tool is not None and self.dir_tool is not None) else None

        agents = {
            # üìê Arquiteto de Software
            "arquiteto": Agent(
                role="üèóÔ∏è Arquiteto de Software S√™nior",
                goal=("Analisar profundamente a arquitetura da aplica√ß√£o, identificando:\n"
                      "- Padr√µes arquiteturais usados (MVC, Clean Architecture, etc.)\n"
                      "- Qualidade das integra√ß√µes com APIs externas\n"
                      "- Escalabilidade e manutenibilidade do c√≥digo\n"
                      "- Pontos de falha e gargalos potenciais\n"
                      "- Sugest√µes concretas de refatora√ß√£o"),
                backstory=("Arquiteto de software com 10+ anos de experi√™ncia em sistemas distribu√≠dos,\n"
                          "APIs de redes sociais e automa√ß√£o. Especialista em Instagram Graph API v23, WhatsApp Business API\n"
                          "e arquiteturas para SaaS. Conhece profundamente padr√µes como Repository, Factory, Observer e\n"
                          "estrat√©gias de rate limiting para APIs."),
                tools=tools_list,
                verbose=True,
                max_iter=3,
                allow_delegation=False,
            ),

            # üß™ Engenheiro de Qualidade
            "qa_engineer": Agent(
                role="üî¨ Engenheiro de Qualidade e Testes",
                goal=("Avaliar rigorosamente a qualidade do c√≥digo:\n"
                      "- Cobertura de testes (unit√°rios, integra√ß√£o, E2E)\n"
                      "- An√°lise est√°tica de c√≥digo (complexity, duplication)\n"
                      "- Pr√°ticas de CI/CD e deployment\n"
                      "- Identifica√ß√£o de bugs e vulnerabilidades\n"
                      "- Estrat√©gias de monitoramento e observabilidade"),
                backstory=("Engenheiro de QA com expertise em automa√ß√£o de testes, an√°lise est√°tica\n"
                          "e pipelines CI/CD. Experi√™ncia com pytest, bandit, ruff e ferramentas de seguran√ßa.\n"
                          "Especialista em testes de APIs, mock de servi√ßos externos e estrat√©gias de teste para\n"
                          "sistemas que integram redes sociais."),
                tools=tools_list,
                verbose=True,
                max_iter=3,
                allow_delegation=False,
            ),

            # üìÑ Documentador T√©cnico
            "documentador": Agent(
                role="üìö Documentador T√©cnico S√™nior",
                goal=("Garantir documenta√ß√£o de classe mundial:\n"
                      "- Clareza para onboarding de desenvolvedores\n"
                      "- Completude da documenta√ß√£o de APIs\n"
                      "- Guias de instala√ß√£o e configura√ß√£o\n"
                      "- Exemplos pr√°ticos e troubleshooting\n"
                      "- Documenta√ß√£o de arquitetura e decis√µes t√©cnicas"),
                backstory=("Documentador t√©cnico especializado em projetos open-source e SaaS.\n"
                          "Expert em criar documenta√ß√£o que funciona para diferentes n√≠veis t√©cnicos,\n"
                          "desde devs juniores at√© arquitetos seniores. Conhece ferramentas como Sphinx,\n"
                          "MkDocs e padr√µes de documenta√ß√£o de APIs REST."),
                tools=tools_list,
                verbose=True,
                max_iter=3,
                allow_delegation=False,
            ),

            # üöÄ Product Manager
            "product_manager": Agent(
                role="üéØ Product Manager Estrat√©gico",
                goal=("Avaliar viabilidade comercial e estrat√©gica:\n"
                      "- Prontid√£o para lan√ßamento como SaaS\n"
                      "- An√°lise competitiva e diferencia√ß√£o\n"
                      "- Roadmap de features e prioriza√ß√£o\n"
                      "- Estrat√©gia de monetiza√ß√£o\n"
                      "- Riscos de ado√ß√£o e go-to-market"),
                backstory=("Product Manager com 8+ anos em produtos de automa√ß√£o e marketing digital.\n"
                          "Experi√™ncia em lan√ßar SaaS para redes sociais, conhece profundamente o mercado de\n"
                          "automa√ß√£o Instagram/WhatsApp. Expert em definir MVP, pricing strategy e user journey\n"
                          "para produtos B2B."),
                tools=tools_list,
                verbose=True,
                max_iter=3,
                allow_delegation=False,
            ),

            # ‚öñÔ∏è Especialista Legal
            "especialista_legal": Agent(
                role="‚öñÔ∏è Consultor Jur√≠dico de Tecnologia",
                goal=("Assegurar conformidade legal total:\n"
                      "- Compliance com termos das APIs (Instagram, WhatsApp)\n"
                      "- Conformidade LGPD/GDPR para dados pessoais\n"
                      "- Riscos legais de automa√ß√£o em redes sociais\n"
                      "- Pol√≠ticas de uso e termos de servi√ßo\n"
                      "- Estrat√©gias de mitiga√ß√£o de riscos legais"),
                backstory=("Advogado especializado em direito digital com foco em APIs de redes sociais.\n"
                          "Expert em LGPD, GDPR e regulamenta√ß√µes de automa√ß√£o. Experi√™ncia em revisar contratos\n"
                          "de APIs, pol√≠ticas de uso de dados e compliance para startups de tecnologia."),
                tools=tools_list,
                verbose=True,
                max_iter=3,
                allow_delegation=False,
            ),

            # ü§ñ Engenheiro de IA
            "engenheiro_ia": Agent(
                role="üß† Engenheiro de IA Especialista",
                goal=("Otimizar componentes de intelig√™ncia artificial:\n"
                      "- An√°lise do pipeline de gera√ß√£o de legendas\n"
                      "- Otimiza√ß√£o de prompts e modelos LLM\n"
                      "- Estrat√©gias de personaliza√ß√£o por usu√°rio\n"
                      "- Performance e custos de APIs de IA\n"
                      "- Implementa√ß√£o de RAG e fine-tuning"),
                backstory=("Engenheiro de IA com especializa√ß√£o em NLP, vis√£o computacional e LLMs.\n"
                          "Experi√™ncia com Google Gemini, OpenAI GPT, e modelos de vis√£o para an√°lise de imagens.\n"
                          "Expert em otimiza√ß√£o de prompts, RAG systems e estrat√©gias de personaliza√ß√£o de conte√∫do\n"
                          "para redes sociais."),
                tools=tools_list,
                verbose=True,
                max_iter=3,
                allow_delegation=False,
            ),
        }

        return agents

    
    def _create_tasks(self) -> List[Task]:
        """üìã Cria tasks espec√≠ficas para cada agente"""
        
        tasks = [
            # Task do Arquiteto
            Task(
                description="""üìê AN√ÅLISE ARQUITETURAL COMPLETA
                
                Leia o arquivo 'relatorio_codebase_turbinado.md' e conduza uma an√°lise arquitetural profunda:
                
                1. **Arquitetura Atual**: Descreva o padr√£o arquitetural identificado
                2. **Integra√ß√µes**: Analise as integra√ß√µes com APIs externas (Instagram, WhatsApp, Gemini)
                3. **Fluxo de Dados**: Mapeie o fluxo de dados de ponta a ponta
                4. **Escalabilidade**: Identifique gargalos e pontos de falha
                5. **Padr√µes de Design**: Liste padr√µes usados e ausentes
                6. **Refatora√ß√µes Sugeridas**: Proponha melhorias concretas com prioriza√ß√£o
                
                Foque em aspectos t√©cnicos profundos e seja espec√≠fico nas recomenda√ß√µes.""",
                expected_output="""An√°lise arquitetural estruturada em se√ß√µes:
                - Resumo da arquitetura atual
                - Qualidade das integra√ß√µes
                - Pontos cr√≠ticos identificados
                - Recomenda√ß√µes priorizadas (Alta/M√©dia/Baixa)
                - Diagrama conceitual em texto
                """,
                agent=self.agents["arquiteto"]
            ),
            
            # Task do QA Engineer
            Task(
                description="""üß™ AVALIA√á√ÉO DE QUALIDADE E TESTES
                
                Analise o relat√≥rio focando em qualidade de c√≥digo e estrat√©gias de teste:
                
                1. **Cobertura de Testes**: Avalie testes existentes (unit√°rios, integra√ß√£o, E2E)
                2. **Qualidade do C√≥digo**: Analise complexity, duplica√ß√£o, code smells
                3. **Seguran√ßa**: Identifique vulnerabilidades e riscos de seguran√ßa
                4. **CI/CD Pipeline**: Avalie pr√°ticas de deployment e automa√ß√£o
                5. **Monitoramento**: Analise estrat√©gias de logging e observabilidade
                6. **Plano de Testes**: Sugira estrat√©gia completa de testes
                
                Seja espec√≠fico em m√©tricas e ferramentas recomendadas.""",
                expected_output="""Relat√≥rio de qualidade estruturado:
                - Score de qualidade atual (0-100)
                - Gaps cr√≠ticos em testes
                - Vulnerabilidades identificadas
                - Estrat√©gia de testes recomendada
                - Ferramentas e m√©tricas sugeridas
                - Roadmap de melhorias em qualidade
                """,
                agent=self.agents["qa_engineer"]
            ),
            
            # Task do Documentador
            Task(
                description="""üìÑ AUDITORIA DE DOCUMENTA√á√ÉO
                
                Avalie a completude e qualidade da documenta√ß√£o existente:
                
                1. **Documenta√ß√£o de Usu√°rio**: Avalie clareza para usu√°rios finais
                2. **Documenta√ß√£o T√©cnica**: Analise docs para desenvolvedores
                3. **API Documentation**: Verifique documenta√ß√£o de endpoints
                4. **Onboarding**: Avalie facilidade de setup para novos devs
                5. **Exemplos Pr√°ticos**: Analise qualidade dos exemplos
                6. **Manuten√ß√£o**: Avalie processo de atualiza√ß√£o da documenta√ß√£o
                
                Priorize aspectos que impactam ado√ß√£o e produtividade.""",
                expected_output="""Auditoria de documenta√ß√£o:
                - Score de completude (0-100)
                - Gaps cr√≠ticos identificados
                - Sugest√µes de reorganiza√ß√£o
                - Templates recomendados
                - Estrat√©gia de manuten√ß√£o
                - Roadmap de melhorias documentais
                """,
                agent=self.agents["documentador"]
            ),
            
            # Task do Product Manager
            Task(
                description="""üöÄ AN√ÅLISE DE VIABILIDADE COMERCIAL
                
                Avalie a prontid√£o do produto para o mercado:
                
                1. **Market Readiness**: Analise maturidade para lan√ßamento SaaS
                2. **Competitive Analysis**: Compare com solu√ß√µes existentes
                3. **Value Proposition**: Identifique diferenciadores √∫nicos
                4. **User Journey**: Mapeie jornada do usu√°rio ideal
                5. **Monetization**: Sugira modelos de precifica√ß√£o
                6. **Go-to-Market**: Proponha estrat√©gia de lan√ßamento
                
                Foque em aspectos que impactam success comercial.""",
                expected_output="""An√°lise comercial estrat√©gica:
                - Score de prontid√£o para mercado (0-100)
                - An√°lise competitiva resumida
                - Proposta de valor √∫nica
                - Roadmap de lan√ßamento em fases
                - Modelo de monetiza√ß√£o sugerido
                - Riscos comerciais e mitiga√ß√µes
                """,
                agent=self.agents["product_manager"]
            ),
            
            # Task do Especialista Legal
            Task(
                description="""‚öñÔ∏è AN√ÅLISE DE CONFORMIDADE LEGAL
                
                Conduza uma auditoria legal completa do projeto:
                
                1. **API Terms Compliance**: Analise conformidade com termos das APIs
                2. **Data Privacy**: Avalie conformidade LGPD/GDPR
                3. **Automation Risks**: Identifique riscos legais de automa√ß√£o
                4. **Terms of Service**: Sugira pol√≠tica de uso adequada
                5. **Liability Issues**: Mapeie responsabilidades e riscos
                6. **Compliance Strategy**: Proponha plano de conformidade
                
                Priorize riscos que podem impactar opera√ß√£o ou lan√ßamento.""",
                expected_output="""Relat√≥rio de conformidade legal:
                - Score de compliance (0-100)
                - Riscos legais cr√≠ticos
                - N√£o conformidades identificadas
                - Plano de adequa√ß√£o legal
                - Pol√≠ticas necess√°rias
                - Roadmap de compliance
                """,
                agent=self.agents["especialista_legal"]
            ),
            
            # Task do Engenheiro de IA
            Task(
                description="""ü§ñ OTIMIZA√á√ÉO DO PIPELINE DE IA
                
                Analise e otimize os componentes de intelig√™ncia artificial:
                
                1. **LLM Integration**: Avalie uso atual do Gemini e outros LLMs
                2. **Prompt Engineering**: Analise qualidade dos prompts
                3. **Performance**: Avalie lat√™ncia e custos de APIs de IA
                4. **Personalization**: Sugira estrat√©gias de personaliza√ß√£o
                5. **Model Selection**: Avalie adequa√ß√£o dos modelos escolhidos
                6. **AI Strategy**: Proponha roadmap de melhorias em IA
                
                Foque em otimiza√ß√µes que impactam UX e custos operacionais.""",
                expected_output="""An√°lise de IA estrat√©gica:
                - Score de otimiza√ß√£o IA (0-100)
                - Bottlenecks identificados
                - Oportunidades de melhoria
                - Estrat√©gia de personaliza√ß√£o
                - Otimiza√ß√µes de custo sugeridas
                - Roadmap de evolu√ß√£o IA
                """,
                agent=self.agents["engenheiro_ia"]
            )
        ]
        
        return tasks
    
    def create_final_report_task(self) -> Task:
        """üìë Cria task final para consolida√ß√£o do relat√≥rio"""
        
        return Task(
            description="""üéØ CONSOLIDA√á√ÉO DO RELAT√ìRIO FINAL
            
            Com base em todas as an√°lises anteriores, crie um relat√≥rio ultra-profissional com:
            
            ## üìä ESTRUTURA DO RELAT√ìRIO FINAL:
            
            ### üéØ EXECUTIVE SUMMARY
            - Score geral do projeto (0-100)
            - Principais for√ßas e fraquezas
            - Recomenda√ß√£o de go/no-go
            
            ### üë∂ SE√á√ÉO PARA DEVS JUNIORES
            - Explica√ß√£o simples da arquitetura
            - Conceitos t√©cnicos com analogias
            - Passos claros para contribuir
            - Recursos de aprendizado
            
            ### üöÄ SE√á√ÉO PARA DEVS SENIORES
            - An√°lise t√©cnica profunda
            - Diagramas e fluxos detalhados
            - Decis√µes arquiteturais cr√≠ticas
            - Trade-offs e justificativas
            
            ### üìà ROADMAP ESTRAT√âGICO
            - Fase 1: Corre√ß√µes cr√≠ticas (0-3 meses)
            - Fase 2: Melhorias estruturais (3-6 meses)  
            - Fase 3: Expans√£o e otimiza√ß√£o (6-12 meses)
            
            ### ‚ö° QUICK WINS
            - A√ß√µes de alto impacto e baixo esfor√ßo
            - Implementa√ß√µes imediatas
            
            ### üö® RISCOS CR√çTICOS
            - Top 5 riscos priorizados
            - Planos de mitiga√ß√£o
            
            Use markdown profissional com emojis, tabelas e formata√ß√£o clara.""",
            expected_output="""Relat√≥rio final em markdown com:
            - Executive summary executivo
            - Se√ß√µes para diferentes p√∫blicos
            - Roadmap detalhado e priorizado
            - M√©tricas e scores quantitativos
            - Recomenda√ß√µes acion√°veis
            - Formata√ß√£o profissional
            """,
            agent=self.agents["arquiteto"],  # Arquiteto como consolidador final
            # NOTE: n√£o passamos `context=self.tasks` aqui porque o modelo Task pode n√£o aceitar objetos complexos.
            # O contexto completo ser√° anexado textualmente √† `description` antes da execu√ß√£o final.
        )
    
    def  run_analysis(self, report_path: str = "relatorio_codebase_turbinado.md",
                     max_files: int = 300,
                     max_size_bytes: int = 2 * 1024 * 1024) -> str:
        """üöÄ Percorre a codebase lendo arquivos e gerando relat√≥rio por arquivo, depois consolida.

        Comportamento:
        - Se `report_path` existe como arquivo: usa o fluxo original (usa o relat√≥rio como insumo).
        - Caso contr√°rio: trata `report_path` como diret√≥rio (se for) ou usa cwd como root e
          analisa arquivos da codebase gerando relat√≥rios por arquivo.
        - Para evitar custos/overload, existe um limite `max_files` e um limite de tamanho por arquivo.
        """
        logger.info("üöÄ Iniciando an√°lise completa da codebase (an√°lise por arquivo)...")

        # Se for arquivo existente, mantemos o comportamento original (usa o relat√≥rio como insumo)
        if os.path.exists(report_path) and os.path.isfile(report_path):
            logger.info(f"üìÑ Relat√≥rio de entrada encontrado: {report_path} ‚Äî executando fluxo padr√£o.")
            # Reutiliza o fluxo original: verifica e executa crew com as tasks definidas mais a task final
            all_tasks = self.tasks + [self.create_final_report_task()]

            crew = Crew(
                agents=list(self.agents.values()),
                tasks=all_tasks,
                process=Process.sequential,
                verbose=True,
                # Avoid initializing persistent memory here to prevent external
                # dependencies (e.g. Chroma) from being required in minimal runs.
                # Per-file runs use memory=False already.
                memory=False,
            )

            try:
                logger.info("üîÑ Executando an√°lise com CrewAI (fluxo padr√£o)...")
                result = crew.kickoff()

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = f"relatorio_final_startup_{timestamp}.md"
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(str(result))

                metadata = {
                    "timestamp": timestamp,
                    "input_file": report_path,
                    "output_file": output_file,
                    "agents_used": list(self.agents.keys()),
                    "total_tasks": len(all_tasks),
                    "llm_model": "gemini-2.5-flash"
                }
                metadata_file = f"metadata_analise_{timestamp}.json"
                with open(metadata_file, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False)

                logger.info("‚úÖ An√°lise conclu√≠da (fluxo padr√£o)!")
                logger.info(f"üìÑ Relat√≥rio salvo em: {output_file}")
                logger.info(f"üìä Metadados salvos em: {metadata_file}")
                return output_file

            except Exception as e:
                logger.error(f"‚ùå Erro durante an√°lise (fluxo padr√£o): {e}")
                raise

        # Caso contr√°rio, tratamos report_path como diret√≥rio ou usamos cwd
        if os.path.isdir(report_path):
            root_dir = report_path
            logger.info(f"üìÅ Usando diret√≥rio informado como root da codebase: {root_dir}")
        else:
            # report_path n√£o existe como arquivo nem diret√≥rio -> usamos cwd como fallback
            root_dir = os.getcwd()
            logger.warning(f"‚ö†Ô∏è '{report_path}' n√£o encontrado como arquivo; usando root: {root_dir}")

        # filtros e extens√µes de interesse
        skip_dirs = {".git", "__pycache__", "node_modules", "venv", ".venv", ".idea", ".env", ".venv"}
        allowed_exts = {".py", ".md", ".txt", ".json", ".yaml", ".yml", ".ini", ".cfg", ".sh", ".tsx", ".ts", ".js"}

        per_file_reports = []
        reports_dir = os.path.join(os.getcwd(), "reports_by_file")
        os.makedirs(reports_dir, exist_ok=True)

        files_analyzed = 0

        # Percorre arquivos
        for dirpath, dirnames, filenames in os.walk(root_dir):
            # pular diret√≥rios indesejados
            dirnames[:] = [d for d in dirnames if d not in skip_dirs]

            for fname in filenames:
                if files_analyzed >= max_files:
                    logger.info(f"‚ÑπÔ∏è Limite de arquivos alcan√ßado ({max_files}). Parando an√°lise por arquivo.")
                    break

                _, ext = os.path.splitext(fname)
                if ext.lower() not in allowed_exts:
                    continue

                file_path = os.path.join(dirpath, fname)

                # evitar arquivos bin√°rios grandes
                try:
                    size = os.path.getsize(file_path)
                    if size > max_size_bytes:
                        logger.info(f"‚è≠Ô∏è Pulando arquivo grande (>{max_size_bytes} bytes): {file_path}")
                        continue
                except Exception:
                    logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel ler tamanho do arquivo, pulando: {file_path}")
                    continue

                try:
                    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Falha ao ler {file_path}: {e}")
                    continue

                # Trunca conte√∫do muito grande para colocar no prompt
                max_chars = 50000
                snippet = content if len(content) <= max_chars else content[:max_chars] + "\n\n... (truncated)"

                logger.info(f"üîé Gerando an√°lise para: {file_path}")

                # Cria task dedicada para o arquivo (usando arquiteto como analista por arquivo)
                per_file_task = Task(
                    description=f"""AN√ÅLISE DO ARQUIVO: {os.path.relpath(file_path, root_dir)}

Leia atentamente o conte√∫do do arquivo abaixo e gere um relat√≥rio focado em:
- Fun√ß√£o do arquivo no projeto (responsabilidade)
- Pontos de acoplamento e depend√™ncias externas
- Complexidade e sugest√µes de refatora√ß√£o
- Riscos de seguran√ßa ou m√° pr√°ticas
- Recomenda√ß√µes de testes (unit√°rios/integracÃßaÃÉo)

Conte√∫do do arquivo (at√© {max_chars} chars):
```
{snippet}
```""",
                    expected_output="""Relat√≥rio por arquivo em markdown com:
- Resumo (1-3 linhas)
- Pontos cr√≠ticos e recomenda√ß√µes
- Sugest√µes de testes
- Linha de a√ß√£o r√°pida (quick win)
""",
                    agent=self.agents["arquiteto"]
                )

                # Executa uma execu√ß√£o r√°pida da crew apenas para este arquivo
                result = None
                try:
                    crew_single = Crew(
                        agents=[self.agents["arquiteto"]],
                        tasks=[per_file_task],
                        process=Process.sequential,
                        verbose=False,
                        memory=False,
                    )
                    result = crew_single.kickoff()
                except Exception as e:
                    logger.error(f"‚ùå Erro ao analisar {file_path}: {e}")
                    # registramos o erro no resultado para posterior salvamento
                    result = f"‚ùå Erro ao analisar {file_path}: {e}"

                # Salva relat√≥rio por arquivo (sempre tentamos salvar, mesmo que a an√°lise falhe)
                safe_name = os.path.relpath(file_path, root_dir).replace(os.sep, "_").replace("..", "")
                if not safe_name:
                    safe_name = fname
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                out_name = f"{safe_name}_{timestamp}.md"
                out_path = os.path.join(reports_dir, out_name)
                try:
                    with open(out_path, "w", encoding="utf-8") as f:
                        f.write(f"# An√°lise do arquivo: {os.path.relpath(file_path, root_dir)}\n\n")
                        f.write(str(result) if result is not None else "(sem resultado)")
                    per_file_reports.append({"file": os.path.relpath(file_path, root_dir), "report_path": out_path})
                    files_analyzed += 1
                    logger.info(f"‚úÖ Relat√≥rio salvo: {out_path} ({files_analyzed}/{max_files})")
                except Exception as e:
                    logger.error(f"‚ùå Falha ao salvar relat√≥rio para {file_path}: {e}")
                    # mesmo se salvar falhar, continuamos com os pr√≥ximos arquivos
                    continue

            if files_analyzed >= max_files:
                break

        if not per_file_reports:
            logger.error("‚ùå Nenhum arquivo foi analisado. Verifique permiss√µes, filtros e paths.")
            raise FileNotFoundError("Nenhum arquivo eleg√≠vel encontrado para an√°lise.")

        # Cria task final de consolida√ß√£o incluindo lista de relat√≥rios por arquivo
        final_task = self.create_final_report_task()
        # Anexa sum√°rio dos relat√≥rios por arquivo na descri√ß√£o para fornecer contexto
        reports_summary_lines = [f"- {r['file']}: {r['report_path']}" for r in per_file_reports]
        reports_summary = "\n".join(reports_summary_lines)
        final_task.description += f"\n\n\n\n**Relat√≥rios por arquivo (resumo):**\n{reports_summary}\n"

        # Executa a consolida√ß√£o final usando toda a crew
        try:
            logger.info("üîÑ Executando consolida√ß√£o final com todos os agentes...")
            crew_all = Crew(
                agents=list(self.agents.values()),
                tasks=[final_task],
                process=Process.sequential,
                verbose=True,
                # disable memory to avoid requiring Chroma or other external
                # vectorstore env vars during light-weight consolidation runs
                memory=False,
            )
            final_result = crew_all.kickoff()

            # Salva resultado final consolidado
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"relatorio_final_startup_{timestamp}.md"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(str(final_result))

            # Salva metadados
            metadata = {
                "timestamp": timestamp,
                "root_dir": root_dir,
                "per_file_reports": per_file_reports,
                "output_file": output_file,
                "agents_used": list(self.agents.keys()),
                "total_files_analyzed": len(per_file_reports),
                "llm_model": "gemini-2.5-flash",
            }
            metadata_file = f"metadata_analise_{timestamp}.json"
            with open(metadata_file, "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            logger.info("‚úÖ Consolida√ß√£o conclu√≠da!")
            logger.info(f"üìÑ Relat√≥rio final: {output_file}")
            logger.info(f"üìÅ Relat√≥rios por arquivo em: {reports_dir}")
            logger.info(f"üìä Metadados salvos em: {metadata_file}")

            return output_file
        except Exception as e:
            # Se a consolida√ß√£o com a Crew falhar (por exemplo, valida√ß√£o de env vars
            # de mem√≥ria vetorial), geramos um fallback: concatenamos todos os
            # relat√≥rios por arquivo salvos e produzimos um relat√≥rio final simples.
            logger.error(f"‚ùå Erro durante consolida√ß√£o com Crew (usando fallback): {e}")
            try:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                fallback_output = f"relatorio_final_fallback_{timestamp}.md"
                with open(fallback_output, "w", encoding="utf-8") as out_f:
                    out_f.write("# Relat√≥rio Consolidado (fallback)\n\n")
                    out_f.write("_A consolida√ß√£o autom√°tica com a Crew falhou; este √© um fallback que concatena os relat√≥rios por arquivo gerados previamente._\n\n")

                    for r in per_file_reports:
                        try:
                            out_f.write(f"\n---\n\n## Arquivo: {r['file']}\n\n")
                            with open(r["report_path"], "r", encoding="utf-8", errors="ignore") as in_f:
                                out_f.write(in_f.read())
                                out_f.write("\n\n")
                        except Exception as inner_e:
                            out_f.write(f"\n(Erro ao incluir {r['file']}: {inner_e})\n")

                metadata = {
                    "timestamp": timestamp,
                    "root_dir": root_dir,
                    "per_file_reports": per_file_reports,
                    "output_file": fallback_output,
                    "agents_used": list(self.agents.keys()),
                    "total_files_analyzed": len(per_file_reports),
                    "llm_model": "gemini-2.5-flash",
                    "fallback": True,
                    "error": str(e),
                }
                metadata_file = f"metadata_analise_{timestamp}.json"
                with open(metadata_file, "w", encoding="utf-8") as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False)

                logger.info("‚úÖ Fallback de consolida√ß√£o conclu√≠do")
                logger.info(f"üìÑ Relat√≥rio final (fallback): {fallback_output}")
                logger.info(f"üìÅ Relat√≥rios por arquivo em: {reports_dir}")
                logger.info(f"üìä Metadados salvos em: {metadata_file}")

                return fallback_output
            except Exception as final_e:
                logger.error(f"‚ùå Falha ao gerar fallback de consolida√ß√£o: {final_e}")
                # Re-raise o erro original para que o caller saiba que algo deu errado
                raise


def main():
    """üéØ Fun√ß√£o principal para execu√ß√£o direta"""
    
    print("üöÄ CrewAI - An√°lise Completa de Codebase")
    print("=" * 50)
    
    try:
        # Inicializa a crew
        crew_analyzer = CodebaseAnalysisCrew()

        # Executa an√°lise (se o relat√≥rio n√£o existir, run_analysis far√° a varredura da codebase)
        report_path = "relatorio_codebase_turbinado.md"
        # Use max_files=3 for quick testing with a valid API key
        output_file = crew_analyzer.run_analysis(report_path, max_files=3)

        print("\nüéâ An√°lise conclu√≠da com sucesso!")
        print(f"üìÑ Relat√≥rio final: {output_file}")
        print("\nüëÄ Visualize o relat√≥rio com:")
        print(f"   cat {output_file}")

    except Exception as e:
        print(f"‚ùå Erro: {str(e)}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
